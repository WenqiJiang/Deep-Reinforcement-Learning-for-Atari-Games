# Deep-Reinforcement-Learning-for-Atari-Games
## see our :point_right:[REPORT](https://github.com/WenqiJiang/Deep-Reinforcement-Learning-for-Atari-Games/blob/master/Report_Deep_Reinforcement_Learning_for_Atari_Games.pdf):point_left: to see implementation details
## Introduction
We train our agents to play Breakout, one of the most popular Atari games. Several deep reinforcement learning algorithms are implemented and compared: Deep Q Learning, Deep SARSA, Double DQN and Dueling DQN, and each algorithm employs two kinds of convolutional structures:
LeNet and VGG-16. Due to the limited computational resources, we set a fixed training step to see which method performs best. Experiment shows that Dueling DQN with LeNet performs the best over other methods.
## Concolusion
In this paper, we first give a brief introduction of Deep Learning, Reinforcement Learning and their combination - Deep Reinforcement Learning. Then we continue to focus on one specific game in Atari 2600 game series - Breakout. In this project, we implement and compare several Deep Reinforcement Learning algorithms: Deep Q Learning, Sarsa, Double DQN and Dueling DQN, using LeNet or VGG-16 on CNN part. After we take a deep look into different Reinforcement Learning methods, we implement them and achieve final results.   
  
We analyze the results and find that among the methods we use, Dueling DQN has the best episode reward and better stability in loss and episode reward. DQN and Double DQN have approximately the same performance, but the latter one has better stability and reliability. SARSA is much worse than the other methods due to limited training time but has clearer trend to converge. When using VGG-16, due to the huge CNN network, we spend tremendous amount of time training the model. However, because of the limited time, we achieve an underfitting network which lead to poor results.   
  
In the future, we could make some improvements: First, we can train longer for better results. In our project, due to the lack of computational resources as well as limited time, all the Reinforcement Learning methods are not given enough time to converge in the end. Results would be further improved and will be clearer to be shown if we continue to train these models. Second, in our project, we can implement more latest methods in recent Reinforcement Learning researches. For improvement, we will implement other up-to-date methods as well as making some improvement on existing methods for better performance.  
